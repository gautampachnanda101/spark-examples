{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum as spark_sum, avg, count, when\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkTutorial\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(\"SparkSession ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f638483b",
   "metadata": {},
   "source": [
    "## 1. Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332af56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data\n",
    "data = [\n",
    "    (1, \"Alice\", \"Engineering\", 75000),\n",
    "    (2, \"Bob\", \"Marketing\", 65000),\n",
    "    (3, \"Charlie\", \"Engineering\", 80000),\n",
    "    (4, \"Diana\", \"Sales\", 70000),\n",
    "    (5, \"Eve\", \"Engineering\", 72000)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"department\", \"salary\"]\n",
    "\n",
    "employees = spark.createDataFrame(data, columns)\n",
    "employees.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a322cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check schema\n",
    "employees.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d412a",
   "metadata": {},
   "source": [
    "## 2. Basic Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda45dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "employees.select(\"name\", \"salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows\n",
    "engineers = employees.filter(col(\"department\") == \"Engineering\")\n",
    "engineers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add computed column\n",
    "with_bonus = employees.withColumn(\"bonus\", col(\"salary\") * 0.10)\n",
    "with_bonus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b8d012",
   "metadata": {},
   "source": [
    "## 3. Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570af993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by department\n",
    "dept_stats = employees.groupBy(\"department\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    avg(\"salary\").alias(\"avg_salary\"),\n",
    "    spark_sum(\"salary\").alias(\"total_salary\")\n",
    ")\n",
    "dept_stats.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18153",
   "metadata": {},
   "source": [
    "## 4. Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7ae188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register temp view\n",
    "employees.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# Run SQL query\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT department, COUNT(*) as cnt, AVG(salary) as avg_sal\n",
    "    FROM employees\n",
    "    GROUP BY department\n",
    "    ORDER BY avg_sal DESC\n",
    "\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2483e",
   "metadata": {},
   "source": [
    "## 5. Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84369f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import row_number, rank\n",
    "\n",
    "# Rank employees by salary within department\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(col(\"salary\").desc())\n",
    "\n",
    "ranked = employees.withColumn(\"rank\", rank().over(window_spec))\n",
    "ranked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a742a8",
   "metadata": {},
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop SparkSession when done\n",
    "spark.stop()\n",
    "print(\"SparkSession stopped\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
